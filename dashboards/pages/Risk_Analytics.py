# dashboards/pages/Risk_Analytics.py
import os, json, glob
import pandas as pd
import streamlit as st

# graceful Plotly import (add plotly>=5.24 and pandas>=2.2 to requirements.txt)
try:
    import plotly.express as px
    import plotly.graph_objects as go
except ModuleNotFoundError:
    st.error("Plotly is required for Risk Analytics. Add `plotly>=5.24` to requirements.txt and redeploy.")
    st.stop()

st.set_page_config(page_title="Risk Analytics", layout="wide")
st.title("AI Audit-as-Code — Risk Analytics & Fix-It")

st.markdown("""
Upload the **batch summary CSV** (generated by `audits/tools/batch_eval.py` or `batch_eval_per_scenario.py`) — 
it contains `decision`, `missing_evidence`, `policy_blockers`, `validator_blockers`, etc.

This page shows:
- **Quadrant (TI vs XI)** and **ARS distribution**
- A **per-scenario Fix-It panel**: what failed, why, and concrete actions
- **Radar** of TI/XI/ARS vs thresholds
- **XI breakdown** (if scenario JSONs are in the repo) and **evidence presence** heat
""")

# ---------------- helpers ----------------

def parse_list(val: str):
    if pd.isna(val) or not str(val).strip():
        return []
    return [x for x in str(val).split(";") if x]

def normalize_summary(df: pd.DataFrame) -> pd.DataFrame:
    # expected fields from batch evaluator
    for c in ["TI","XI","ARS","R"]:
        if c not in df.columns:
            df[c] = 0.0
        df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0.0)

    if "recommendation" not in df.columns:
        # derive from decision + ARS
        def rec_from(ars, decision):
            if decision == "FAIL" or float(ars) < 0.40: return "BLOCK"
            if ars < 0.55: return "SANDBOX"
            if ars < 0.70: return "PILOT"
            if ars < 0.85: return "DEPLOY WITH CONTROLS"
            return "DEPLOY WITH AUDIT"
        df["recommendation"] = [rec_from(a, d) for a, d in zip(df["ARS"], df.get("decision","PASS"))]

    if "decision" not in df.columns:
        # derive from recommendation (BLOCK -> FAIL else PASS)
        df["decision"] = df["recommendation"].apply(lambda x: "FAIL" if str(x).strip().upper()=="BLOCK" else "PASS")

    for name in ["missing_evidence","policy_blockers","validator_blockers"]:
        if name not in df.columns:
            df[name] = ""

    if "scenario" not in df.columns:
        # fall back to row index
        df["scenario"] = [f"scenario_{i+1}" for i in range(len(df))]

    return df

FIX_PLAYBOOK = {
    # evidence
    "dataset": "Produce dataset.json with a content hash (e.g., SHA-256) and tie it to model/data cards.",
    "model_card": "Add model_card.json: model intent, data, metrics, limitations; reference dataset hash.",
    "data_card": "Add data_card.json: provenance, sampling, consent, pre-processing, splits; include dataset hash.",
    "lineage": "Add lineage.json with {container, python, git, seed}; pin container digest and commit hash.",
    "risk": "Add risk.json with composite risk + method; include uncertainty bands if possible.",
    "audit_trail": "Add audit_trail.json: timestamped steps (train, explain, review) with actor and outcome.",
    "replication": "Add replication.json: exact steps, seeds, hardware, env vars; enable one-click reruns.",
    "local_fidelity": "Improve local_fidelity (e.g., calibrated surrogates, monotonic constraints, feature checks).",
    "global_stability": "Stabilize explanations across perturbations; average across runs; seed control.",
    "faithfulness": "Use deletion/insertion tests; remove spurious features; prefer faithful XAI methods.",
    "robustness": "Adversarial/noise/shift tests; add guards and robust training; calibrate outputs.",
    "coverage": "Ensure explanation coverage across classes/regions; target >= 0.8 coverage.",
    "human_comprehensibility": "Simplify explanations; human-friendly labels; reduce dimensionality; add examples.",
    # blockers
    "high_residual_risk": "Lower R: strengthen red-teaming, add input/output filters, tool-use restrictions, and rate limits.",
    "missing_traceability": "Provide lineage.json and link artifacts (model/data cards, logs) for full traceability.",
    "fairness_minority_gap": "Reduce group disparity: rebalancing, reweighting, post-processing (e.g., equalized odds), threshold tuning, more diverse data.",
    "pii_leakage_scan": "Eliminate PII leaks: de-identify training data; add runtime PII filters; re-scan and re-train."
}

def load_scenario_artifacts(scenario_name: str) -> dict:
    """
    Try standard locations committed to repo (works on Streamlit Cloud):
    scenarios_100_v2/<scenario>/*.json  OR  scenarios_100/<scenario>/*.json
    """
    bases = ["scenarios_100_v2", "scenarios_100"]
    for b in bases:
        d = os.path.join(b, scenario_name)
        if os.path.isdir(d):
            artifacts = {}
            for p in glob.glob(os.path.join(d, "*.json")):
                key = os.path.splitext(os.path.basename(p))[0]
                try:
                    artifacts[key] = json.load(open(p, "r", encoding="utf-8"))
                except Exception:
                    pass
            return artifacts
    return {}

def xi_breakdown_from_artifacts(artifacts: dict) -> dict:
    # Best-effort extraction; keys may be absent
    def take(k, key="score", fallback=None):
        if k in artifacts:
            v = artifacts[k].get(key)
            if v is None and "score" in artifacts[k]:
                v = artifacts[k]["score"]
            if v is None:
                # alternative keys
                for alt in ["consistency","validity","stability"]:
                    if alt in artifacts[k]:
                        v = artifacts[k][alt]
                        break
            return float(v) if v is not None else fallback
        return fallback
    parts = {
        "local_fidelity": take("local_fidelity", fallback=None),
        "global_stability": take("global_stability", fallback=None),
        "faithfulness": take("faithfulness", fallback=None),
        "robustness": take("robustness", fallback=None),
        "coverage": take("coverage", fallback=None),
        "human_comprehensibility": take("human_comprehensibility", fallback=None),
        "shap_consistency": take("shap", key="consistency", fallback=None),
        "cf_validity": take("counterfactuals", key="validity", fallback=None),
        "saliency_stability": take("saliency", key="stability", fallback=None),
    }
    # Filter None values
    return {k:v for k,v in parts.items() if v is not None}

def evidence_presence_from_artifacts(artifacts: dict) -> dict:
    keys = [
        "dataset","model_card","data_card","lineage","risk","audit_trail","replication",
        "local_fidelity","global_stability","faithfulness","robustness","coverage","human_comprehensibility",
        "fairness","pii_scan","redteam","shap","counterfactuals","saliency"
    ]
    return {k: (k in artifacts) for k in keys}

# ---------------- inputs ----------------

colA, colB = st.columns([1,1])
with colA:
    csv_file = st.file_uploader("Upload **batch summary CSV** (e.g., reports/audit_results/summary_strict.csv)", type=["csv"])
with colB:
    st.write("Tip: Generate this with:")
    st.code("python -m audits.tools.batch_eval --policy policies/tracex.policy.v2.yaml --root scenarios_100_v2 --mode strict --out reports/audit_results")

if csv_file is None:
    st.info("Upload the **summary_*.csv** produced by the batch evaluator.")
    st.stop()

df = pd.read_csv(csv_file)
df = normalize_summary(df)

# ---------------- overview ----------------

st.markdown("### Overview")
c1, c2, c3, c4, c5 = st.columns(5)
c1.metric("Scenarios", f"{len(df):,}")
c2.metric("PASS", int((df["decision"]=="PASS").sum()))
c3.metric("FAIL", int((df["decision"]=="FAIL").sum()))
c4.metric("Mean ARS", f"{pd.to_numeric(df['ARS']).mean():.2f}")
c5.metric("Mean XI", f"{pd.to_numeric(df['XI']).mean():.2f}")

st.markdown("### TI vs XI Quadrant")
quad = px.scatter(
    df, x="TI", y="XI",
    color="recommendation",
    hover_data=["scenario","ARS","R","decision","policy_blockers","validator_blockers"],
    opacity=0.85
)
quad.update_layout(height=480)
st.plotly_chart(quad, use_container_width=True)

st.markdown("### ARS Distribution by Recommendation")
hist = px.histogram(df, x="ARS", color="recommendation", nbins=30, barmode="overlay", opacity=0.75)
hist.update_layout(height=320)
st.plotly_chart(hist, use_container_width=True)

# ---------------- per-scenario Fix-It ----------------

st.markdown("## Scenario Fix-It Panel")
scen = st.selectbox("Pick a scenario", df["scenario"].tolist())

# thresholds (defaults to v2 policy; you can edit live)
with st.expander("Thresholds", expanded=False):
    th_ti = st.number_input("TI threshold", value=0.75, step=0.01)
    th_xi = st.number_input("XI threshold", value=0.72, step=0.01)
    th_ars = st.number_input("ARS threshold", value=0.74, step=0.01)

row = df[df["scenario"]==scen].iloc[0]
ti, xi, ars, r = float(row["TI"]), float(row["XI"]), float(row["ARS"]), float(row["R"])
decision = row["decision"]
rec = row["recommendation"]

# Radar (scenario vs thresholds)
radar = go.Figure()
radar.add_trace(go.Scatterpolar(r=[ti, xi, ars], theta=["TI","XI","ARS"], fill="toself", name="Scenario"))
radar.add_trace(go.Scatterpolar(r=[th_ti, th_xi, th_ars], theta=["TI","XI","ARS"], name="Thresholds"))
radar.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0,1])), showlegend=True, height=420)
st.plotly_chart(radar, use_container_width=True)

# Deficits table (where it lacks)
deficits = []
if ti < th_ti: deficits.append({"Area":"TI","Current":round(ti,3),"Target":th_ti,"Delta":round(th_ti-ti,3),"Fix":"Add lineage; pin env; sign attestation"})
if xi < th_xi: deficits.append({"Area":"XI","Current":round(xi,3),"Target":th_xi,"Delta":round(th_xi-xi,3),"Fix":"Improve XAI quality: stability, faithfulness, coverage"})
if ars < th_ars: deficits.append({"Area":"ARS","Current":round(ars,3),"Target":th_ars,"Delta":round(th_ars-ars,3),"Fix":"Raise readiness via risk controls and/or TI/XI improvements"})
def_df = pd.DataFrame(deficits) if deficits else pd.DataFrame([{"Area":"—","Current":"—","Target":"—","Delta":"—","Fix":"No metric below threshold"}])

cA, cB = st.columns([1.1,1])
with cA:
    st.markdown("### What’s below threshold?")
    st.dataframe(def_df, use_container_width=True, hide_index=True)
with cB:
    st.markdown("### Decision")
    st.metric("Gate Decision", decision)
    st.metric("Recommendation", rec)
    st.metric("Residual Risk (R)", f"{r:.2f}")

# Missing evidence & blockers → Fix recommendations
missing = parse_list(row["missing_evidence"])
pblks = parse_list(row["policy_blockers"])
vblks = parse_list(row["validator_blockers"])
all_blks = pblks + vblks

def rec_for_item(item):
    return FIX_PLAYBOOK.get(item, "Add or remediate this evidence/blocker per your policy controls.")

fix_rows = []
for ev in missing:
    fix_rows.append({"Type":"Missing evidence", "Item":ev, "How to fix": rec_for_item(ev)})
for b in all_blks:
    fix_rows.append({"Type":"Blocker", "Item":b, "How to fix": rec_for_item(b)})

# If no explicit missing/blockers, still give guidance from deficits
if not fix_rows and deficits:
    for d in deficits:
        k = d["Area"]
        item = "TI low" if k=="TI" else ("XI low" if k=="XI" else "ARS low")
        fix_rows.append({"Type":"Metric deficit", "Item":item, "How to fix": rec_for_item(item.replace(" ", "_"))})

st.markdown("### Fix-It Recommendations")
fix_df = pd.DataFrame(fix_rows) if fix_rows else pd.DataFrame([{"Type":"—","Item":"—","How to fix":"No blockers or missing evidence; meets thresholds."}])
st.dataframe(fix_df, use_container_width=True, hide_index=True)

# Deep-dive: read scenario JSONs if they exist in the repo → XI breakdown + evidence presence heat
artifacts = load_scenario_artifacts(scen)
if artifacts:
    st.markdown("### XI Breakdown (from scenario artifacts)")
    parts = xi_breakdown_from_artifacts(artifacts)
    if parts:
        xidf = pd.DataFrame({"metric": list(parts.keys()), "score": [float(v) for v in parts.values()]})
        bar = px.bar(xidf, x="metric", y="score", range_y=[0,1])
        bar.update_layout(height=320, xaxis_tickangle=-30)
        st.plotly_chart(bar, use_container_width=True)
    else:
        st.caption("No detailed explainability JSONs found for this scenario (local_fidelity, faithfulness, etc.).")

    st.markdown("### Evidence Presence")
    presence = evidence_presence_from_artifacts(artifacts)
    presdf = pd.DataFrame({"evidence": list(presence.keys()), "present": ["Yes" if v else "No" for v in presence.values()]})
    presdf["present_num"] = [1 if v=="Yes" else 0 for v in presdf["present"]]
    heat = px.imshow(presdf[["present_num"]].T, labels=dict(x="Evidence", y="Present?"), 
                     x=presdf["evidence"].tolist(), y=["present"], color_continuous_scale=["#ffdddd","#a6e3a1"])
    heat.update_layout(height=180, coloraxis_showscale=False)
    st.plotly_chart(heat, use_container_width=True)
else:
    st.caption("Scenario artifacts not found in the repo (looked under scenarios_100_v2/ and scenarios_100/). "
               "You’ll still get Fix-It guidance from the CSV.")
